# План миграции с pandas на polars для okx_data_saver

## Обзор изменений

Данный план описывает пошаговую миграцию кода с библиотеки pandas на polars в файлах `main/show_plot/processor.py` и `main/show_plot/gui/window.py`. Polars предоставляет более быструю работу с данными и лучшую производительность для больших датасетов.

## Основные различия между pandas и polars

### 1. Импорты и типы данных
- **pandas**: `DataFrame`, `Series`, `pandas.Timestamp`
- **polars**: `pl.DataFrame`, `pl.Series`, `pl.Datetime`

### 2. Основные операции
- **pandas**: `.loc[]`, `.itertuples()`, `.index`, `.array`
- **polars**: `.filter()`, `.iter_rows()`, `.get_column()`, `.to_numpy()`

### 3. Создание DataFrame
- **pandas**: `DataFrame.from_records()`
- **polars**: `pl.DataFrame()`

### 4. Работа с индексами
- **pandas**: `.set_index()`, `.index`
- **polars**: `.with_columns()`, `.get_column()`

## Пошаговый план миграции

### Этап 1: Подготовка и установка зависимостей

1. **Добавить polars в requirements.txt**
   ```txt
   polars>=0.20.0
   ```

2. **Обновить импорты в processor.py**
   ```python
   # Заменить
   import pandas
   from pandas import DataFrame, Series

   # На
   import polars as pl
   from polars import DataFrame, Series
   ```

3. **Обновить импорты в window.py**
   ```python
   # Заменить
   import pandas

   # На
   import polars as pl
   ```

### Этап 2: Миграция типов данных и аннотаций

4. **Обновить типы в processor.py**
   ```python
   # Заменить все упоминания
   pandas.DataFrame → pl.DataFrame
   pandas.Series → pl.Series
   pandas.Timestamp → pl.Datetime
   ```

5. **Обновить типы в window.py**
   ```python
   # Заменить
   pandas.Timestamp → pl.Datetime
   pandas.Series → pl.Series
   ```

### Этап 3: Миграция создания DataFrame

6. **Заменить DataFrame.from_records() в processor.py**
   ```python
   # Было
   new_candle_dataframe = DataFrame.from_records(
       candle_raw_data_list,
       columns=[...]
   )

   # Станет
   new_candle_dataframe = pl.DataFrame(candle_raw_data_list)
   ```

7. **Заменить pandas.read_sql_query() в processor.py**
   ```python
   # Было
   for order_book_dataframe_chunk in pandas.read_sql_query(...)

   # Станет
   for order_book_dataframe_chunk in pl.read_database(...)
   ```

### Этап 4: Миграция операций с данными

8. **Заменить операции с индексами в processor.py**
   ```python
   # Было
   trades_dataframe.loc[trades_dataframe.index >= min_trade_id]

   # Станет
   trades_dataframe.filter(pl.col("trade_id") >= min_trade_id)
   ```

9. **Заменить itertuples() в processor.py**
   ```python
   # Было
   for trade_data in trades_dataframe.itertuples():
       trade_id = trade_data.Index

   # Станет
   for row in trades_dataframe.iter_rows(named=True):
       trade_id = row["trade_id"]
   ```

10. **Заменить операции с Series в processor.py**
    ```python
    # Было
    price_series.max()
    price_series.min()
    price_series.size

    # Станет
    price_series.max()
    price_series.min()
    price_series.height  # или len(price_series)
    ```

### Этап 5: Миграция работы с временными метками

11. **Заменить pandas.to_datetime() в processor.py**
    ```python
    # Было
    new_candle_dataframe.end_timestamp_ms = pandas.to_datetime(
        new_candle_dataframe.end_timestamp_ms,
        unit='ms'
    )

    # Станет
    new_candle_dataframe = new_candle_dataframe.with_columns(
        pl.col("end_timestamp_ms").cast(pl.Datetime("ms"))
    )
    ```

12. **Заменить работу с Timestamp в window.py**
    ```python
    # Было
    start_timestamp: pandas.Timestamp = candle_row_data.start_timestamp_ms
    start_timestamp_ms = int(start_timestamp.timestamp() * 1000)

    # Станет
    start_timestamp: pl.Datetime = candle_row_data.start_timestamp_ms
    start_timestamp_ms = int(start_timestamp.timestamp() * 1000)
    ```

### Этап 6: Миграция операций сортировки и индексации

13. **Заменить set_index() и sort_values() в processor.py**
    ```python
    # Было
    new_candle_dataframe.set_index('start_trade_id', inplace=True)
    new_candle_dataframe.sort_values('start_trade_id', inplace=True)

    # Станет
    new_candle_dataframe = new_candle_dataframe.sort('start_trade_id')
    # В polars нет концепции индекса, используем колонки напрямую
    ```

14. **Заменить combine_first() в processor.py**
    ```python
    # Было
    candle_dataframe = old_candle_dataframe.combine_first(new_candle_dataframe)

    # Станет
    candle_dataframe = pl.concat([old_candle_dataframe, new_candle_dataframe])
    # Или использовать join операции для более сложной логики
    ```

### Этап 7: Миграция операций с массивами

15. **Заменить .array и .index в window.py**
    ```python
    # Было
    self.__price_plot_data_item.setData(
        price_series.index,
        price_series.array
    )

    # Станет
    self.__price_plot_data_item.setData(
        price_series.get_column("trade_id").to_numpy(),
        price_series.get_column("price").to_numpy()
    )
    ```

### Этап 8: Миграция операций с DataFrame в GUI

16. **Заменить itertuples() в window.py**
    ```python
    # Было
    for candle_row_data in candle_dataframe.itertuples():
        start_trade_id = candle_row_data.Index

    # Станет
    for row in candle_dataframe.iter_rows(named=True):
        start_trade_id = row["start_trade_id"]
    ```

17. **Заменить операции с Timestamp в window.py**
    ```python
    # Было
    start_timestamp.value
    end_timestamp.value - start_timestamp.value

    # Станет
    start_timestamp.timestamp() * 1000  # если нужно в миллисекундах
    (end_timestamp - start_timestamp).total_seconds() * 1000
    ```

### Этап 9: Обновление операций с Series

18. **Заменить операции с Series в processor.py**
    ```python
    # Было
    bollinger_base_line_series.index
    bollinger_base_line_series.array

    # Станет
    bollinger_base_line_series.get_column("index").to_numpy()
    bollinger_base_line_series.get_column("values").to_numpy()
    ```

### Этап 10: Тестирование и оптимизация

19. **Создать тесты для проверки корректности миграции**
    - Сравнить результаты операций pandas vs polars
    - Проверить производительность
    - Убедиться в корректности отображения графиков

20. **Оптимизировать производительность**
    - Использовать lazy evaluation polars где возможно
    - Оптимизировать операции с большими датасетами
    - Проверить использование памяти

## Дополнительные соображения

### Производительность
- Polars обычно быстрее pandas для больших датасетов
- Lazy evaluation может значительно ускорить операции
- Лучшая работа с памятью

### Совместимость
- Некоторые операции могут работать по-разному
- Необходимо тщательное тестирование
- Возможны изменения в API

### Откат
- Сохранить оригинальные файлы
- Создать ветку для миграции
- Подготовить план отката при проблемах

## Ожидаемые результаты

1. **Улучшение производительности** - особенно для больших датасетов
2. **Лучшее использование памяти** - polars более эффективен
3. **Современный API** - более выразительный и функциональный
4. **Лучшая типизация** - polars лучше интегрируется с type hints

## Риски и митигация

1. **Изменение поведения** - тщательное тестирование
2. **Совместимость с pyqtgraph** - проверка интеграции
3. **Производительность GUI** - мониторинг отзывчивости
4. **Сложность миграции** - пошаговый подход с тестированием

## Временные рамки

- **Этапы 1-3**: 1-2 дня (подготовка и базовые изменения)
- **Этапы 4-8**: 3-5 дней (основная миграция)
- **Этапы 9-10**: 2-3 дня (тестирование и оптимизация)
- **Общее время**: 1-2 недели